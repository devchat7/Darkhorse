{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "final_qb_data = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv\")\n",
    "final_qb_data['YearsBack'] = 2024 - final_qb_data['season'].astype(int)\n",
    "final_qb_data.to_csv('/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv')\n",
    "final_rb_data = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv\")\n",
    "final_rb_data['YearsBack'] = 2024 - final_rb_data['season'].astype(int)\n",
    "final_rb_data.to_csv('/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv')\n",
    "final_wrte_data = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv\")\n",
    "final_wrte_data['YearsBack'] = 2024 - final_wrte_data['season'].astype(int)\n",
    "final_wrte_data.to_csv('/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv')\n",
    "\n",
    "def dfMaker():\n",
    "     #if ppr is 0 it is non ppr, if it is 1 it is half ppr, if its 2 it is full ppr. loops through\n",
    "    for ppr in range(3):\n",
    "        \n",
    "        #read csv files into pandas\n",
    "        oldQBStats = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv\")\n",
    "        oldRBStats = pd.read_csv('/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv')\n",
    "        oldWRTEStats = pd.read_csv('/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv')\n",
    "        currTeamsRoster = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/currYearRoster.csv\")\n",
    "        pastTeamsRoster = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/teamsPastRoster.csv\")\n",
    "        currAVs = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "        #make empty dfs and list to put players into\n",
    "        completeDFQB = pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks', 'sack_yards', 'sack_fumbles',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_epa', 'passing_2pt_conversions', 'pacr',\n",
    "       'dakota', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa',\n",
    "       'rushing_2pt_conversions', 'games', 'ppr_sh',\n",
    "       'status', 'comp %', 'td:int', 'yards/attempts', 'yards/comp',\n",
    "       'yards/carry', 'passer rating', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "        completeDFRB= pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n",
    "       'wopr_x', 'special_teams_tds', 'fantasy_points', 'games', 'tgt_sh',\n",
    "       'ay_sh', 'yac_sh', 'wopr_y', 'ry_sh', 'rtd_sh', 'rfd_sh', 'rtdfd_sh',\n",
    "       'dom', 'w8dom', 'yptmpa', 'ppr_sh', 'age', 'status', 'y/c', 'y/g',\n",
    "       'c/g', 'y/rec', 'rec/g', 'y/tgt', 'catch %', 'touches', 'y/touch',\n",
    "       'rrtd', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "        completeDFWRTE= pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n",
    "       'wopr_x', 'special_teams_tds', 'fantasy_points', 'games', 'tgt_sh',\n",
    "       'ay_sh', 'yac_sh', 'wopr_y', 'ry_sh', 'rtd_sh', 'rfd_sh', 'rtdfd_sh',\n",
    "       'dom', 'w8dom', 'yptmpa', 'ppr_sh', 'age', 'status', 'y/c', 'y/g',\n",
    "       'c/g', 'y/rec', 'rec/g', 'y/tgt', 'catch %', 'touches', 'y/touch',\n",
    "       'rrtd', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "        rookieList = []\n",
    "\n",
    "        f = 0\n",
    "\n",
    "        for index in range(len(currTeamsRoster)):\n",
    "\n",
    "            f+=1\n",
    "            #boolean to break if rookie\n",
    "            breakBool = False\n",
    "\n",
    "            #years back variable\n",
    "            x = 1\n",
    "\n",
    "            #penalty variable for injuries\n",
    "            penalty = 0\n",
    "\n",
    "            #current players place to store information\n",
    "            individualDFQB = pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks', 'sack_yards', 'sack_fumbles',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_epa', 'passing_2pt_conversions', 'pacr',\n",
    "       'dakota', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa',\n",
    "       'rushing_2pt_conversions', 'games', 'ppr_sh',\n",
    "       'status', 'comp %', 'td:int', 'yards/attempts', 'yards/comp',\n",
    "       'yards/carry', 'passer rating', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "            individualDFRB = pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n",
    "       'wopr_x', 'special_teams_tds', 'fantasy_points', 'games', 'tgt_sh',\n",
    "       'ay_sh', 'yac_sh', 'wopr_y', 'ry_sh', 'rtd_sh', 'rfd_sh', 'rtdfd_sh',\n",
    "       'dom', 'w8dom', 'yptmpa', 'ppr_sh', 'age', 'status', 'y/c', 'y/g',\n",
    "       'c/g', 'y/rec', 'rec/g', 'y/tgt', 'catch %', 'touches', 'y/touch',\n",
    "       'rrtd', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "            individualDFWRTE = pd.DataFrame(columns= [\"team\", \"position\", \"penalty\", \"GP\", \"player_display_name\", \"age\", 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n",
    "       'wopr_x', 'special_teams_tds', 'fantasy_points', 'games', 'tgt_sh',\n",
    "       'ay_sh', 'yac_sh', 'wopr_y', 'ry_sh', 'rtd_sh', 'rfd_sh', 'rtdfd_sh',\n",
    "       'dom', 'w8dom', 'yptmpa', 'ppr_sh', 'age', 'status', 'y/c', 'y/g',\n",
    "       'c/g', 'y/rec', 'rec/g', 'y/tgt', 'catch %', 'touches', 'y/touch',\n",
    "       'rrtd', \"PPG\", \"oline\", \"rb\", \"wr\", \"qb\", \"te\"])\n",
    "            individualDFQB.loc[0] = [0] * len(individualDFQB.columns)\n",
    "            individualDFRB.loc[0] = [0] * len(individualDFRB.columns)\n",
    "            individualDFWRTE.loc[0] = [0] * len(individualDFWRTE.columns)\n",
    "\n",
    "            #current players informaton\n",
    "            year = currTeamsRoster.loc[index, 'Yrs']\n",
    "            bday = currTeamsRoster.loc[index, 'BirthDate']\n",
    "            pos = currTeamsRoster.loc[index, 'Pos']\n",
    "            age = currTeamsRoster.loc[index, 'Age']\n",
    "            name = currTeamsRoster.loc[index, 'Player']\n",
    "            team = currTeamsRoster.loc[index, 'Team']\n",
    "\n",
    "            games = 0\n",
    "\n",
    "            #see if rookie\n",
    "            if year == \"Rook\":\n",
    "                #add player to rookie column\n",
    "                dict = {}\n",
    "                dict = {\"Name\": name, \"Year\": year, \"Bday\": bday, \"Age\": age, \"Team\": team}\n",
    "                rookieList.append(dict)\n",
    "                breakBool = True\n",
    "\n",
    "                continue\n",
    "\n",
    "            while True:\n",
    "            \n",
    "                #get all player rows from past year\n",
    "                playerRowRoster = pastTeamsRoster.loc[(pastTeamsRoster['Player'] == name) & (pastTeamsRoster[\"YearsBack\"] == x) & (pastTeamsRoster[\"BirthDate\"] == bday)].copy()\n",
    "                playerRowRoster = playerRowRoster.reset_index()\n",
    "                \n",
    "                #if there is no data for player it goes back to find data until years back (x) > 3\n",
    "                if playerRowRoster.empty:\n",
    "                    \n",
    "                    if x>3:\n",
    "                        if games>6:\n",
    "                            #breaks if needed number of games is aqcuired.\n",
    "                            break\n",
    "                        elif (int(year)<4):\n",
    "                            #add player to rookie column\n",
    "                            dict = {}\n",
    "                            dict = {\"Name\": name, \"Year\": year, \"Bday\": bday, \"Age\": age, \"Team\": team}\n",
    "                            rookieList.append(dict)\n",
    "                            breakBool = True\n",
    "\n",
    "                            #breaks if cannot go back another year\n",
    "                            break\n",
    "                        else:\n",
    "                            breakBool = True\n",
    "                            break\n",
    "\n",
    "                    x=x+1\n",
    "                    continue\n",
    "            \n",
    "                for ind in range(len(playerRowRoster)):\n",
    "                    teamCurr = playerRowRoster.loc[ind, \"Team\"]\n",
    "                    numberCurr = playerRowRoster.loc[ind, \"No.\"]\n",
    "                    \n",
    "\n",
    "                    if pos == \"QB\":\n",
    "                        #gets correct player using team name, player name, and player number\n",
    "                        playerRowStats = oldQBStats.loc[(oldQBStats[\"team\"]== teamCurr) & (oldQBStats[\"player_display_name\"]==name) & (oldQBStats[\"YearsBack\"]==x)]\n",
    "                        playerRowStats = playerRowStats.reset_index() \n",
    "                        playerRowStats = playerRowStats.fillna(0)\n",
    "\n",
    "                        if playerRowStats.empty:\n",
    "                            continue\n",
    "                                                    \n",
    "                        columns_to_update = [\n",
    "                        'completions', 'attempts', 'passing_yards', 'passing_tds', 'interceptions',\n",
    "                        'sacks', 'sack_yards', 'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards',\n",
    "                        'passing_yards_after_catch', 'passing_first_downs', 'passing_epa', 'passing_2pt_conversions',\n",
    "                        'pacr', 'dakota', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles',\n",
    "                        'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa', 'rushing_2pt_conversions', 'ppr_sh', 'comp %', 'td:int',\n",
    "                        'yards/attempts', 'yards/comp', 'yards/carry', 'passer rating'\n",
    "                        ]\n",
    "\n",
    "                        for column in columns_to_update:\n",
    "                            individualDFQB[column] = playerRowStats.loc[0, column] + individualDFQB[column]\n",
    "    \n",
    "                        \n",
    "                        games = games + playerRowStats.loc[0, \"GP\"]\n",
    "                    \n",
    "                    elif pos == \"RB\":\n",
    "                        playerRowStats = oldRBStats.loc[(oldRBStats[\"team\"]== teamCurr) & (oldRBStats[\"player_display_name\"]==name) & (oldRBStats[\"YearsBack\"]==x)]\n",
    "                        playerRowStats = playerRowStats.reset_index() \n",
    "                        playerRowStats = playerRowStats.fillna(0)\n",
    "\n",
    "                        if playerRowStats.empty:\n",
    "                            continue\n",
    "\n",
    "                        columns_to_update = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "                        'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "                        'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "                        'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "                        'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "                        'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "                        'receiving_2pt_conversions','special_teams_tds',\n",
    "                        'rrtd']\n",
    "\n",
    "                        for column in columns_to_update:\n",
    "                            individualDFRB[column] = playerRowStats.loc[0, column] + individualDFRB[column]\n",
    "                            \n",
    "                    elif pos in ['WR','TE']:\n",
    "                        playerRowStats = oldWRTEStats.loc[(oldQBStats[\"team\"]== teamCurr) & (oldWRTEStats[\"player_display_name\"]==name) & (oldWRTEStats[\"YearsBack\"]==x)]\n",
    "                        playerRowStats = playerRowStats.reset_index() \n",
    "                        playerRowStats = playerRowStats.fillna(0)\n",
    "\n",
    "                        if playerRowStats.empty:\n",
    "                            continue\n",
    "\n",
    "                        columns_to_update = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "                        'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "                        'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "                        'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "                        'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "                        'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "                        'receiving_2pt_conversions','special_teams_tds',\n",
    "                        'rrtd']\n",
    "\n",
    "                        for column in columns_to_update:\n",
    "                            individualDFWRTE[column] = playerRowStats.loc[0, column] + individualDFWRTE[column]\n",
    "\n",
    "                    if (x==1):\n",
    "                        penalty = penalty + playerRowStats.loc[0, \"GP\"]   \n",
    "                    elif (x==2):\n",
    "                        penalty = penalty + (playerRowStats.loc[0, \"GP\"]*0.9)   \n",
    "                    elif (x==3):\n",
    "                        penalty = penalty + (playerRowStats.loc[0, \"GP\"]*0.8)   \n",
    "                    elif (x==4):\n",
    "                        penalty = penalty + (playerRowStats.loc[0, \"GP\"]*0.7)   \n",
    "                \n",
    "                if (games<6) and (x>3) and (int(year)<4):\n",
    "                    #add player to rookie column\n",
    "                    dict = {}\n",
    "                    dict = {\"Name\": name, \"Year\": year, \"Bday\": bday, \"Age\": age, \"Team\": team}\n",
    "                    rookieList.append(dict)\n",
    "                    breakBool = True\n",
    "                    break\n",
    "                elif (games<6) and (x>3):\n",
    "                    breakBool = True\n",
    "                    break\n",
    "                if (games>6) or (x>3):\n",
    "                    break\n",
    "\n",
    "                x+=1\n",
    "\n",
    "                        #break if rookie\n",
    "            if (breakBool == True):\n",
    "                continue\n",
    "\n",
    "            if pos == \"QB\":\n",
    "                #make it all per game not total\n",
    "                columns_to_update = [\n",
    "                        'completions', 'attempts', 'passing_yards', 'passing_tds', 'interceptions',\n",
    "                        'sacks', 'sack_yards', 'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards',\n",
    "                        'passing_yards_after_catch', 'passing_first_downs', 'passing_2pt_conversions',\n",
    "                        'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles',\n",
    "                        'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions'\n",
    "                ]\n",
    "                for column in columns_to_update:\n",
    "                        individualDFQB[column] = individualDFQB[column] / games\n",
    "                individualDFQB[\"player_display_name\"] = name\n",
    "                individualDFQB[\"position\"] = pos\n",
    "                individualDFQB[\"team\"] = team\n",
    "                individualDFQB[\"GP\"] = games\n",
    "                individualDFQB[\"penalty\"] = penalty/games\n",
    "\n",
    "                individualDFQB.loc[:, \"PPG\"] = (individualDFQB[\"rushing_yards\"]*0.1) + (individualDFQB[\"passing_yards\"]*.04) + (individualDFQB[\"rushing_tds\"]*6) + (individualDFQB[\"passing_tds\"]*4) + (individualDFQB[\"rushing_fumbles\"]*-2) + (individualDFQB[\"sack_fumbles\"]*-2) + (individualDFQB[\"interceptions\"]*-2)\n",
    "                individualDFQB.loc[:, \"PPG\"] = individualDFQB[\"PPG\"]\n",
    "                \n",
    "                #add other columns needed\n",
    "                individualDFQB[\"age\"] = age\n",
    "\n",
    "                #locate row with correct team and pos and add it\n",
    "                rowOL = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFQB['oline'] = rowOL['oline']\n",
    "                \n",
    "                rowRB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFQB['rb'] = rowRB['rb']\n",
    "                        \n",
    "                rowWR = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFQB['wrte'] = rowWR['wrte']\n",
    "\n",
    "                rowQB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFQB['qb'] = rowQB['qb']\n",
    "\n",
    "                rowTE = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFQB['dst'] = rowTE['dst']\n",
    "\n",
    "                completeDFQB = pd.concat([completeDFQB, individualDFQB], ignore_index=True, join=\"inner\")  \n",
    "            elif pos == \"RB\":\n",
    "                columns_to_update = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "                        'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "                        'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "                        'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "                        'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "                        'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "                        'receiving_2pt_conversions','special_teams_tds',\n",
    "                        'rrtd']\n",
    "                for column in columns_to_update:\n",
    "                        individualDFRB[column] = individualDFRB[column] / games\n",
    "                individualDFRB[\"player_display_name\"] = name\n",
    "                individualDFRB[\"position\"] = pos\n",
    "                individualDFRB[\"team\"] = team\n",
    "                individualDFRB[\"GP\"] = games\n",
    "                individualDFRB[\"penalty\"] = penalty/games\n",
    "\n",
    "                individualDFRB.loc[:, \"PPG\"] = (individualDFRB[\"rushing_yards\"]*0.1) + (individualDFRB[\"rushing_tds\"]*6) + (individualDFRB[\"rushing_fumbles\"]*-2)\n",
    "                individualDFRB.loc[:, \"PPG\"] = individualDFRB[\"PPG\"]\n",
    "                \n",
    "                #add other columns needed\n",
    "                individualDFRB[\"age\"] = age\n",
    "\n",
    "                #locate row with correct team and pos and add it\n",
    "                rowOL = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFRB['oline'] = rowOL['oline']\n",
    "                \n",
    "                rowRB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFRB['rb'] = rowRB['rb']\n",
    "                        \n",
    "                rowWR = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFRB['wrte'] = rowWR['wrte']\n",
    "\n",
    "                rowQB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFRB['qb'] = rowQB['qb']\n",
    "\n",
    "                rowTE = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFRB['dst'] = rowTE['dst']\n",
    "\n",
    "                completeDFRB = pd.concat([completeDFRB, individualDFRB], ignore_index=True, join=\"inner\")  \n",
    "            elif pos == \"WRTE\":\n",
    "                columns_to_update = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "                        'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "                        'rushing_epa', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "                        'receiving_yards', 'receiving_tds', 'receiving_fumbles',\n",
    "                        'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "                        'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n",
    "                        'receiving_2pt_conversions','special_teams_tds',\n",
    "                        'rrtd']\n",
    "                for column in columns_to_update:\n",
    "                        individualDFWRTE[column] = individualDFWRTE[column] / games\n",
    "                individualDFWRTE[\"player_display_name\"] = name\n",
    "                individualDFWRTE[\"position\"] = pos\n",
    "                individualDFWRTE[\"team\"] = team\n",
    "                individualDFWRTE[\"GP\"] = games\n",
    "                individualDFWRTE[\"penalty\"] = penalty/games\n",
    "\n",
    "                individualDFWRTE.loc[:, \"PPG\"] = (individualDFWRTE[\"rushing_yards\"]*0.1) + (individualDFQB[\"rushing_tds\"]*6)\n",
    "                individualDFWRTE.loc[:, \"PPG\"] = individualDFWRTE[\"PPG\"]\n",
    "                \n",
    "                #add other columns needed\n",
    "                individualDFWRTE[\"age\"] = age\n",
    "\n",
    "                #locate row with correct team and pos and add it\n",
    "                rowOL = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFWRTE['oline'] = rowOL['oline']\n",
    "                \n",
    "                rowRB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFWRTE['rb'] = rowRB['rb']\n",
    "                        \n",
    "                rowWRTE = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFWRTE['wrte'] = rowWR['wrte']\n",
    "\n",
    "                rowQB = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFWRTE['qb'] = rowQB['qb']\n",
    "\n",
    "                rowDST = currAVs.loc[currAVs['team'] == team].iloc[0]\n",
    "                individualDFWRTE['dst'] = rowDST['dst']\n",
    "\n",
    "                completeDFWRTE = pd.concat([completeDFWRTE, individualDFWRTE], ignore_index=True, join=\"inner\")  \n",
    "                #write into csv based on if ppr or not\n",
    "        if ppr == 0:\n",
    "            completeDFQB = completeDFQB.sort_values(by=['PPG'])\n",
    "            completeDFQB.to_csv(\"QBDFForModelNonPPR.csv\", encoding='utf-8', index=False)\n",
    "            completeDFRB = completeDFRB.sort_values(by=['PPG'])\n",
    "            completeDFRB.to_csv(\"RBDFForModelNonPPR.csv\", encoding='utf-8', index=False)\n",
    "            completeDFWRTE = completeDFWRTE.sort_values(by=['PPG'])\n",
    "            completeDFWRTE.to_csv(\"WRTEDFForModelNonPPR.csv\", encoding='utf-8', index=False)\n",
    "        elif ppr == 1:\n",
    "            completeDFQB = completeDFQB.sort_values(by=['PPG'])\n",
    "            completeDFQB.to_csv(\"QBDFForModelHalfPPR.csv\", encoding='utf-8', index=False)\n",
    "        elif ppr == 2:\n",
    "            completeDFQB = completeDFQB.sort_values(by=['PPG'])\n",
    "            completeDFQB.to_csv(\"QBDFForModelPPR.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "dfMaker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 141\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m ppr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    137\u001b[0m             finalqbs\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_rankings/PPR_rankings/QBs_PPR.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 70\u001b[0m, in \u001b[0;36mscorer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m qbsScaled \u001b[38;5;241m=\u001b[39m qbs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     69\u001b[0m qbsScaled \u001b[38;5;241m=\u001b[39m qbsScaled\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpenalty\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_display_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam\u001b[39m\u001b[38;5;124m\"\u001b[39m])        \n\u001b[0;32m---> 70\u001b[0m qbsScaled[qbsScaled\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqbsScaled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mqbsScaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#have these so it can iterate through easily\u001b[39;00m\n\u001b[1;32m     73\u001b[0m allPosDFs \u001b[38;5;241m=\u001b[39m [qbs]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    465\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    474\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names, but MLPRegressor was fitted without feature names\")\n",
    "\n",
    "#gets ppg back into normal form\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def scorer():\n",
    "\n",
    "    #scaler to scale data\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    #if 0 its non ppr, if 1 its half ppr, if 2 its full ppr. loops through.\n",
    "\n",
    "    for ppr in range(3):\n",
    "        #dict of scores\n",
    "        dictScores = {}\n",
    "\n",
    "        if ppr == 0:\n",
    "            #read in player stats df and make positional dfs\n",
    "            qbs = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/Models/QBDFForModelNonPPR.csv\")\n",
    "\n",
    "            qbModel = joblib.load(\"/Users/kmaran3/Dropbox/Darkhorse/Models/qbModelNonPPR.joblib\")\n",
    "        elif ppr == 1:\n",
    "            #read in player stats df and make positional dfs\n",
    "            qbs = pd.read_csv('/Users/kmaran3/Dropbox/Darkhorse/Models/QBDFForModelHalfPPR.csv')\n",
    "\n",
    "            qbModel = joblib.load(\"/Users/kmaran3/Dropbox/Darkhorse/Models/qbModelHalfPPR.joblib\")\n",
    "        elif ppr == 2:        \n",
    "            #read in player stats df and make positional dfs\n",
    "            qbs = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/Models/QBDFForModelPPR.csv\")\n",
    "\n",
    "            #loads models\n",
    "            qbModel = joblib.load(\"/Users/kmaran3/Dropbox/Darkhorse/Models/qbModelPPR.joblib\")\n",
    "\n",
    "        #dictionary to easily call models\n",
    "        modelsDict = {\"QB\": qbModel}\n",
    "\n",
    "        #gets fantasypoints scale per each position\n",
    "        scaleQB = getScaleBack(qbs)\n",
    "        \n",
    "        qbsScaled = qbs.copy()\n",
    "        qbsScaled = qbsScaled.drop(columns=[\"GP\", \"position\", \"penalty\", \"player_display_name\", \"team\"])        \n",
    "        qbsScaled[qbsScaled.columns] = scaler.fit_transform(qbsScaled[qbsScaled.columns])\n",
    "\n",
    "        #have these so it can iterate through easily\n",
    "        allPosDFs = [qbs]\n",
    "        allPosDfsScaled = [qbsScaled]\n",
    "        scaleBack = [scaleQB]\n",
    "\n",
    "        currPosDict = {}\n",
    "        indPosArr = []\n",
    "\n",
    "        #iterates through each position\n",
    "        for ind in range(len(allPosDFs)):\n",
    "            #gets current position df, scaled current df, and array to help get ppg to normal.\n",
    "            currDF = allPosDFs[ind]\n",
    "            scaled = allPosDfsScaled[ind]\n",
    "            arr = scaleBack[ind]\n",
    "\n",
    "            #dictionary to store current position grades.\n",
    "            currPosDict = {}\n",
    "        \n",
    "            #iterates through all players in current position.\n",
    "            for i in range(len(currDF)):\n",
    "\n",
    "                #gets current information for current player\n",
    "                currRow = currDF.iloc[[i]]\n",
    "                currRow = currRow.reset_index()\n",
    "                scaled = scaled.reset_index()\n",
    "                scaled = scaled.drop(columns=[\"index\"])\n",
    "                currRowForModel = scaled.iloc[[i]] \n",
    "\n",
    "                pos = currRow.loc[0, \"Pos\"]\n",
    "                name = currRow.loc[0, \"Name\"]\n",
    "                penalty = currRow.loc[0, \"Penalty\"]     \n",
    "\n",
    "                #gets in correct positinal model and predicts each player\n",
    "                model = modelsDict[pos]\n",
    "                prediction = model.predict(currRowForModel)  \n",
    "\n",
    "                #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "                prediction = (prediction*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "                #this is where the penalty is added and prediction is entered into the dictionary\n",
    "                currPosDict[name] = prediction[0]*penalty   \n",
    "\n",
    "            #appends current position grades to all of them.\n",
    "            indPosArr.append(currPosDict)\n",
    "\n",
    "            \n",
    "    \n",
    "        #sorts dictionary\n",
    "        finalqbs = indPosArr[3]\n",
    "\n",
    "        finalqbs = dict(sorted(finalqbs.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        n = len(finalqbs)\n",
    "        rankNums = np.arange(1, n+1)\n",
    "        finalqbs = list(finalqbs.keys())\n",
    "        finalqbs = pd.DataFrame(finalqbs, columns=['Name'])\n",
    "        finalqbs.insert(0, \"Rank\", rankNums, True)\n",
    "\n",
    "\n",
    "        #writes into csv files\n",
    "        if ppr == 0:\n",
    "            finalqbs.to_csv(\"final_rankings/NonPPR_rankings/QBs_NonPPR.csv\", encoding='utf-8', index=False)\n",
    "        elif ppr == 1:\n",
    "            finalqbs.to_csv(\"final_rankings/HalfPPR_rankings/QBs_HalfPPR.csv\", encoding='utf-8', index=False)\n",
    "        elif ppr == 2:\n",
    "            finalqbs.to_csv(\"final_rankings/PPR_rankings/QBs_PPR.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\n",
    "scorer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
