{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8207726314870332\n",
      "passing_tds: 0.6126532669158066\n",
      "rushing_yards: 0.10716838168748449\n",
      "passing_yards: 0.09925729633327889\n",
      "carries: 0.07587437312442773\n",
      "rushing_tds: 0.06973244531957129\n",
      "rushing_first_downs: 0.040666698557862896\n",
      "passing_first_downs: 0.02350960043469319\n",
      "interceptions: 0.02022502921456087\n",
      "passing_yards_after_catch: 0.004855832984022546\n",
      "passing_air_yards: 0.003603952908837854\n",
      "qb: 0.0032053219751899563\n",
      "sack_fumbles_lost: 0.001289617938883313\n",
      "passing_2pt_conversions: 0.0011238619141196214\n",
      "rb: 0.0005816515189396254\n",
      "rushing_fumbles_lost: 0.000495423908193593\n",
      "dst: 0.00013568762290885327\n",
      "rushing_2pt_conversions: 3.847197681366099e-05\n",
      "wrte: -0.00016813435144822698\n",
      "oline: -0.0002236699855607649\n",
      "completions: -0.00041897616600684363\n",
      "age: -0.0006641459198772892\n",
      "attempts: -0.002329899884755935\n",
      "sacks: -0.003714440038306438\n",
      "qb score(ppg off on average per player):  0.03332744464062\n",
      "0.825445559728367\n",
      "passing_tds: 0.6146860495760926\n",
      "rushing_yards: 0.10565737150554728\n",
      "passing_yards: 0.09866684963434917\n",
      "rushing_tds: 0.06752827683835576\n",
      "carries: 0.05722489817624625\n",
      "rushing_first_downs: 0.05254748440298666\n",
      "passing_first_downs: 0.02275807767312983\n",
      "interceptions: 0.02060266673456169\n",
      "passing_air_yards: 0.007077338557950869\n",
      "passing_yards_after_catch: 0.00539379497056664\n",
      "qb: 0.0012480188612654397\n",
      "sack_fumbles_lost: 0.0011183623555276023\n",
      "passing_2pt_conversions: 0.0010251432808868377\n",
      "age: 0.0008771562005929102\n",
      "wrte: 0.0007084389527321156\n",
      "rb: 0.0006012388669038338\n",
      "rushing_fumbles_lost: 0.00039045905599310095\n",
      "dst: 6.881450073562001e-05\n",
      "rushing_2pt_conversions: 4.7193190217516e-05\n",
      "oline: -0.00044058938580056274\n",
      "completions: -0.000591898754355954\n",
      "sacks: -0.0014233534555516836\n",
      "attempts: -0.002132719114543545\n",
      "qb score(ppg off on average per player):  0.033022294896968195\n",
      "0.8240657777750781\n",
      "passing_tds: 0.617560089775207\n",
      "passing_yards: 0.1016895554018665\n",
      "rushing_yards: 0.09935725400385237\n",
      "carries: 0.06913143378665991\n",
      "rushing_tds: 0.06626680295304516\n",
      "rushing_first_downs: 0.04249437302779266\n",
      "passing_first_downs: 0.023531509727461538\n",
      "interceptions: 0.019202941781445663\n",
      "passing_yards_after_catch: 0.00563042093193078\n",
      "passing_air_yards: 0.005255532223669741\n",
      "sack_fumbles_lost: 0.0012129668886934075\n",
      "passing_2pt_conversions: 0.0008766473640750728\n",
      "rb: 0.0008420512565428507\n",
      "age: 0.0007749252585826772\n",
      "rushing_fumbles_lost: 0.0007229730797094269\n",
      "wrte: 0.0006322372551497824\n",
      "dst: 0.0005344887064784987\n",
      "qb: 0.0004923331325532377\n",
      "rushing_2pt_conversions: 0.0\n",
      "oline: -0.00018934834223765517\n",
      "completions: -0.0003757389140037004\n",
      "sacks: -0.001472859731924514\n",
      "attempts: -0.0018061868191564946\n",
      "qb score(ppg off on average per player):  0.03332967096574559\n"
     ]
    }
   ],
   "source": [
    "#QB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_2pt_conversions',\n",
    "       'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'fantasy_points', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    pass\n",
    "  elif pprTF == 1:\n",
    "    pass\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 5]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['PPG','season','GP','season_type','age','fantasy_points','completions','attempts','passing_yards','passing_tds','interceptions','sacks','sack_fumbles_lost','passing_air_yards','passing_yards_after_catch','passing_first_downs','passing_2pt_conversions','carries','rushing_yards','rushing_tds','rushing_fumbles_lost','rushing_first_downs','rushing_2pt_conversions']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for feature, importance in sorted_importances:\n",
    "      print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "    return [mae, gbr]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"QB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = getBestParams(dfFantasyCopy, scaleQB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "  print(\"qb score(ppg off on average per player): \", num)\n",
    "\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelPPR.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rushing_yards: 0.19705952635662471\n",
      "rb: 0.08895611684001857\n",
      "carries: 0.04064098182302581\n",
      "rushing_first_downs: 0.018946216681800215\n",
      "rushing_fumbles_lost: 0.004197501934881821\n",
      "dst: 0.0032849529774148212\n",
      "rushing_tds: 0.0015565643158663512\n",
      "rrtd: 0.0008154688750638272\n",
      "wrte: 0.0006088535797573702\n",
      "qb: 0.0005142626594790334\n",
      "special_teams_tds: 0.00014294052556384828\n",
      "receiving_yards: 9.243761813319096e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "receiving_tds: -0.0012080405704691843\n",
      "oline: -0.0023963298329282667\n",
      "receiving_air_yards: -0.007319873034463129\n",
      "targets: -0.008546492663423687\n",
      "receiving_yards_after_catch: -0.010417438677411638\n",
      "receptions: -0.013354227285292904\n",
      "receiving_first_downs: -0.02914880983608337\n",
      "age: -0.03261999042803542\n",
      "rb score(ppg off on average per player):  0.13963064583145904\n",
      "rushing_yards: 0.21915171846215478\n",
      "rb: 0.038677789031732114\n",
      "age: 0.03495162901177484\n",
      "rushing_first_downs: 0.024709998703693975\n",
      "rrtd: 0.018266623267472783\n",
      "receiving_first_downs: 0.017207045439500322\n",
      "receiving_yards_after_catch: 0.016533741116143016\n",
      "receptions: 0.015016160010616942\n",
      "rushing_tds: 0.014591874305244905\n",
      "carries: 0.010741936229772544\n",
      "rushing_fumbles_lost: 0.010386991515612327\n",
      "dst: 0.003942225102895145\n",
      "receiving_yards: 0.0025271829583253837\n",
      "targets: 0.0004323938196016286\n",
      "special_teams_tds: 0.00027117747995905383\n",
      "rushing_2pt_conversions: 0.00017630090148241796\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "receiving_air_yards: -0.00031499981874232974\n",
      "qb: -0.0009434175001929323\n",
      "wrte: -0.00296278456437982\n",
      "receiving_tds: -0.0029789855679998433\n",
      "oline: -0.00514770677562197\n",
      "rb score(ppg off on average per player):  0.12690704061940575\n",
      "rushing_yards: 0.13731586256422643\n",
      "rushing_first_downs: 0.08972036779816887\n",
      "rrtd: 0.02521447373130924\n",
      "rb: 0.02420054629007824\n",
      "oline: 0.012395463113941378\n",
      "receiving_yards_after_catch: 0.011892542657511869\n",
      "wrte: 0.009301856060215961\n",
      "receiving_first_downs: 0.007325323621935425\n",
      "qb: 0.006215619552385121\n",
      "rushing_tds: 0.0027985021602609707\n",
      "dst: 0.0025454423910242297\n",
      "receiving_air_yards: 0.002081447533003703\n",
      "age: 0.0017328039570689967\n",
      "carries: 0.001580846283000581\n",
      "receiving_fumbles_lost: 0.0\n",
      "receiving_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "receiving_tds: -0.0001838211359198827\n",
      "targets: -0.0021525946091074276\n",
      "rushing_2pt_conversions: -0.0021997571974148467\n",
      "receiving_yards: -0.004964473623970157\n",
      "rushing_fumbles_lost: -0.005869695315601536\n",
      "receptions: -0.007674208239515402\n",
      "rb score(ppg off on average per player):  0.12322055787795098\n"
     ]
    }
   ],
   "source": [
    "#RB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age','season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train GradientBoostingRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"RB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleRB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramRB = getBestParams(dfFantasyCopy, scaleRB)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  rbArray = machineLearning(dfFantasyCopy, scaleRB, paramRB)\n",
    "  num = rbArray[0]\n",
    "  rbModel = rbArray[1]\n",
    "\n",
    "  print(\"rb score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(rbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelPPR.joblib\")\n",
    "#print(dfFantasyRB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receiving_air_yards: 0.1250707371682855\n",
      "receiving_yards_after_catch: 0.11229775462159275\n",
      "wrte: 0.03268371579316379\n",
      "targets: 0.0300772544304533\n",
      "qb: 0.029070338016393523\n",
      "oline: 0.014732345111481065\n",
      "receiving_fumbles_lost: 0.0072267401577955\n",
      "receiving_first_downs: 0.002779057502834823\n",
      "receiving_2pt_conversions: 0.0007166515895771075\n",
      "rushing_fumbles_lost: 0.0\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "carries: -0.0003525119852836711\n",
      "rushing_first_downs: -0.0009487166040506978\n",
      "dst: -0.0010783858332679885\n",
      "rrtd: -0.0019367915705777571\n",
      "receiving_tds: -0.004036806736027051\n",
      "receiving_yards: -0.005085659461043456\n",
      "age: -0.0065045047019463235\n",
      "rushing_yards: -0.007901671016131652\n",
      "rushing_tds: -0.011327300845867137\n",
      "rb: -0.011866773880060829\n",
      "receptions: -0.015912024427763526\n",
      "wrte score(ppg off on average per player):  0.11536116042403276\n",
      "receiving_yards: 0.16060506506422306\n",
      "receiving_air_yards: 0.14300933764884516\n",
      "qb: 0.0238652059519602\n",
      "receiving_yards_after_catch: 0.021119153265339002\n",
      "wrte: 0.017037206023805842\n",
      "receiving_first_downs: 0.014481757130831356\n",
      "receptions: 0.01228979661850168\n",
      "age: 0.008239796938438113\n",
      "targets: 0.00517877604028177\n",
      "dst: 0.003760270411035328\n",
      "oline: 0.002734943696510174\n",
      "receiving_fumbles_lost: 0.002351788044589944\n",
      "receiving_2pt_conversions: 0.0014926756624586413\n",
      "rushing_yards: 0.0009529744578373045\n",
      "carries: 0.00042606959016948555\n",
      "rushing_tds: 0.000372551561348321\n",
      "rushing_fumbles_lost: 0.0001536161485032972\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: -5.321479867870238e-08\n",
      "rrtd: -0.0005720436890751335\n",
      "rushing_first_downs: -0.001216107776453028\n",
      "rb: -0.0015923396623997144\n",
      "receiving_tds: -0.0026982443087849597\n",
      "wrte score(ppg off on average per player):  0.11095252719463788\n",
      "receiving_yards: 0.34720185745554744\n",
      "receiving_air_yards: 0.07270284379341484\n",
      "age: 0.013699157240208546\n",
      "receptions: 0.012907990421441418\n",
      "receiving_yards_after_catch: 0.011922749758685534\n",
      "targets: 0.011642003281380537\n",
      "wrte: 0.008801078055690588\n",
      "qb: 0.008051882972020362\n",
      "rushing_yards: 0.004139170613111897\n",
      "receiving_first_downs: 0.0034173627661358507\n",
      "receiving_tds: 0.0030367747891452477\n",
      "carries: 0.002598566807432946\n",
      "rrtd: 0.002554315169277254\n",
      "rb: 0.0006568218556725502\n",
      "oline: 0.0003374023986185004\n",
      "rushing_fumbles_lost: 0.00032052970515978994\n",
      "receiving_fumbles_lost: 3.331121723873287e-05\n",
      "receiving_2pt_conversions: 1.3114019990498882e-05\n",
      "rushing_2pt_conversions: 0.0\n",
      "special_teams_tds: 0.0\n",
      "rushing_first_downs: -0.000379877585817332\n",
      "rushing_tds: -0.0010868934653625129\n",
      "dst: -0.0023570775420734768\n",
      "wrte score(ppg off on average per player):  0.10715394839236987\n"
     ]
    }
   ],
   "source": [
    "#WRTE ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd', 'age']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'age', 'season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"PPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"PPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    gbr = GradientBoostingRegressor(**dictParam)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = gbr.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(gbr, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, gbr, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'max_depth': [3, 4, 5],\n",
    "      'min_samples_split': [2, 3, 4]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  gbr = GradientBoostingRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(gbr, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"PPG\" and 'Unnamed' not in col and col != 'YearsBack']\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"PPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  # print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "  \n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"WRTE\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleWRTE = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramWRTE = getBestParams(dfFantasyCopy, scaleWRTE)\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  wrteArray = machineLearning(dfFantasyCopy, scaleWRTE, paramWRTE)\n",
    "  num = wrteArray[0]\n",
    "  wrteModel = wrteArray[1]\n",
    "\n",
    "  print(\"wrte score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(wrteModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelPPR.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
