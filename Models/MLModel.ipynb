{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qb score(ppg off on average per player):  0.08417874026947322\n",
      "qb score(ppg off on average per player):  0.08678252867284232\n",
      "qb score(ppg off on average per player):  0.06678525411268069\n"
     ]
    }
   ],
   "source": [
    "#QB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_qb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['completions', 'attempts', 'passing_yards',\n",
    "       'passing_tds', 'interceptions', 'sacks',\n",
    "       'sack_fumbles_lost', 'passing_air_yards', 'passing_yards_after_catch',\n",
    "       'passing_first_downs', 'passing_2pt_conversions',\n",
    "       'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'fantasy_points']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    pass\n",
    "  elif pprTF == 1:\n",
    "    pass\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 5]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "def putAV(df, dfAV):\n",
    "  #years to iterate through\n",
    "  yearsBig = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "  teams = [\"crd\", \"atl\", \"rav\", \"buf\", \"car\", \"chi\", \"cin\", \"cle\", \"dal\", \"den\", \"det\", \"gnb\", \"htx\", \"clt\", \"jax\", \"kan\", \"rai\", \"sdg\", \"ram\", \"mia\", \"min\", \"nwe\", \"nor\", \"nyg\", \"nyj\", \"phi\", \"pit\", \"sfo\", \"sea\", \"tam\", \"oti\", \"was\"]\n",
    "\n",
    "  #columns wanted to add\n",
    "  columns = [\"oline\", \"rb\", \"wrte\", \"qb\", \"dst\"]\n",
    "  df[columns] = np.nan\n",
    "\n",
    "  #gets rid of nan for these columns, as when we drop nan we want to save these.\n",
    "  for colNow in columns:\n",
    "    df.loc[df[\"season\"] == 2013, colNow] = \"no\"\n",
    "\n",
    "\n",
    "\n",
    "  #iterates through years\n",
    "  for year in yearsBig:\n",
    "\n",
    "    #assigns df of AVS to only include current year\n",
    "    dfCurr = dfAV[dfAV.season == year].copy()\n",
    "    \n",
    "    #iterates through team list\n",
    "    for teamNow in teams:\n",
    "      #makes the df\n",
    "      dfCurrNew = dfCurr[dfCurr.team == teamNow]\n",
    "      \n",
    "      #iterates through columns and adds AV\n",
    "      for colNow in columns:\n",
    "        #locate correct year and team rows\n",
    "        condition = (df[\"season\"] == year) & (df[\"team\"] == teamNow)\n",
    "\n",
    "        #set these rows to correct values\n",
    "        df.loc[condition, colNow] = dfCurrNew.iloc[0][colNow]\n",
    "\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['PPG','season','GP','season_type','fantasy_points','completions','attempts','passing_yards','passing_tds','interceptions','sacks','sack_fumbles_lost','passing_air_yards','passing_yards_after_catch','passing_first_downs','passing_2pt_conversions','carries','rushing_yards','rushing_tds','rushing_fumbles_lost','rushing_first_downs','rushing_2pt_conversions']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"targetPPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"targetPPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=dictParam[\"hidden_layer_sizes\"], activation=dictParam[\"activation\"], solver=dictParam[\"solver\"], max_iter=dictParam[\"max_iter\"])\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = mlp.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(mlp, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, mlp]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'hidden_layer_sizes': [(32,32), (64,32), (64), (64,64)],\n",
    "      'activation': ['tanh', 'identity', 'logistic', 'relu'],\n",
    "      'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "      'max_iter': [100, 200, 500]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  mlp = MLPRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(mlp, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  print(\"Best things:\", grid_search.best_params_)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = putAV(dfFantasyCopy, dfGrades)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"QB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'max_iter': 300, 'solver': 'adam'}\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "  print(\"qb score(ppg off on average per player): \", num)\n",
    "\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/qb models/qbModelPPR.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rb score(ppg off on average per player):  0.030937026450428385\n",
      "rb score(ppg off on average per player):  0.030639368746275514\n",
      "rb score(ppg off on average per player):  0.024005715291716682\n"
     ]
    }
   ],
   "source": [
    "#RB ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_rb_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "def putAV(df, dfAV):\n",
    "  #years to iterate through\n",
    "  yearsBig = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "  teams = [\"crd\", \"atl\", \"rav\", \"buf\", \"car\", \"chi\", \"cin\", \"cle\", \"dal\", \"den\", \"det\", \"gnb\", \"htx\", \"clt\", \"jax\", \"kan\", \"rai\", \"sdg\", \"ram\", \"mia\", \"min\", \"nwe\", \"nor\", \"nyg\", \"nyj\", \"phi\", \"pit\", \"sfo\", \"sea\", \"tam\", \"oti\", \"was\"]\n",
    "\n",
    "  #columns wanted to add\n",
    "  columns = [\"oline\", \"rb\", \"wrte\", \"qb\", \"dst\"]\n",
    "  df[columns] = np.nan\n",
    "\n",
    "  #gets rid of nan for these columns, as when we drop nan we want to save these.\n",
    "  for colNow in columns:\n",
    "    df.loc[df[\"season\"] == 2013, colNow] = \"no\"\n",
    "\n",
    "\n",
    "\n",
    "  #iterates through years\n",
    "  for year in yearsBig:\n",
    "\n",
    "    #assigns df of AVS to only include current year\n",
    "    dfCurr = dfAV[dfAV.season == year].copy()\n",
    "    \n",
    "    #iterates through team list\n",
    "    for teamNow in teams:\n",
    "      #makes the df\n",
    "      dfCurrNew = dfCurr[dfCurr.team == teamNow]\n",
    "      \n",
    "      #iterates through columns and adds AV\n",
    "      for colNow in columns:\n",
    "        #locate correct year and team rows\n",
    "        condition = (df[\"season\"] == year) & (df[\"team\"] == teamNow)\n",
    "\n",
    "        #set these rows to correct values\n",
    "        df.loc[condition, colNow] = dfCurrNew.iloc[0][colNow]\n",
    "\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"targetPPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"targetPPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=dictParam[\"hidden_layer_sizes\"], activation=dictParam[\"activation\"], solver=dictParam[\"solver\"], max_iter=dictParam[\"max_iter\"])\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = mlp.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(mlp, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    # print(\"Feature importances in descending order:\")\n",
    "    # for feature, importance in sorted_importances:\n",
    "    #     print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, mlp, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'hidden_layer_sizes': [(32,32), (64,32), (64), (64,64)],\n",
    "      'activation': ['tanh', 'identity', 'logistic', 'relu'],\n",
    "      'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "      'max_iter': [100, 200, 500]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  mlp = MLPRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(mlp, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  # print(\"Best things:\", grid_search.best_params_)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = putAV(dfFantasyCopy, dfGrades)\n",
    "\n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"RB\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'max_iter': 300, 'solver': 'adam'}\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "\n",
    "  print(\"rb score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/rb models/rbModelPPR.joblib\")\n",
    "#print(dfFantasyRB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrte score(ppg off on average per player):  0.016811082434313094\n",
      "wrte score(ppg off on average per player):  0.012225431994855096\n",
      "wrte score(ppg off on average per player):  0.01751193412307935\n"
     ]
    }
   ],
   "source": [
    "#WRTE ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "dfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_wrte_data.csv\")\n",
    "dfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = dfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    dfFantasy[column].fillna(dfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points', 'rrtd']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - df[\"receptions\"]\n",
    "  elif pprTF == 1:\n",
    "    df.loc[:, \"fantasy_points\"] = df[\"fantasy_points\"] - (df[\"receptions\"]/2)\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['GP']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['GP'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.GP > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 2]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "def putAV(df, dfAV):\n",
    "  #years to iterate through\n",
    "  yearsBig = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "  teams = [\"crd\", \"atl\", \"rav\", \"buf\", \"car\", \"chi\", \"cin\", \"cle\", \"dal\", \"den\", \"det\", \"gnb\", \"htx\", \"clt\", \"jax\", \"kan\", \"rai\", \"sdg\", \"ram\", \"mia\", \"min\", \"nwe\", \"nor\", \"nyg\", \"nyj\", \"phi\", \"pit\", \"sfo\", \"sea\", \"tam\", \"oti\", \"was\"]\n",
    "\n",
    "  #columns wanted to add\n",
    "  columns = [\"oline\", \"rb\", \"wrte\", \"qb\", \"dst\"]\n",
    "  df[columns] = np.nan\n",
    "\n",
    "  #gets rid of nan for these columns, as when we drop nan we want to save these.\n",
    "  for colNow in columns:\n",
    "    df.loc[df[\"season\"] == 2013, colNow] = \"no\"\n",
    "\n",
    "\n",
    "\n",
    "  #iterates through years\n",
    "  for year in yearsBig:\n",
    "\n",
    "    #assigns df of AVS to only include current year\n",
    "    dfCurr = dfAV[dfAV.season == year].copy()\n",
    "    \n",
    "    #iterates through team list\n",
    "    for teamNow in teams:\n",
    "      #makes the df\n",
    "      dfCurrNew = dfCurr[dfCurr.team == teamNow]\n",
    "      \n",
    "      #iterates through columns and adds AV\n",
    "      for colNow in columns:\n",
    "        #locate correct year and team rows\n",
    "        condition = (df[\"season\"] == year) & (df[\"team\"] == teamNow)\n",
    "\n",
    "        #set these rows to correct values\n",
    "        df.loc[condition, colNow] = dfCurrNew.iloc[0][colNow]\n",
    "\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"GP\", \"season_type\", \"fantasy_points\", \"player_display_name\", \"player_id\", \"team\", \"position\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['player_id', 'season', 'player_display_name', 'team', 'GP', 'position',\n",
    "       'season_type', 'carries', 'rushing_yards', 'rushing_tds',\n",
    "       'rushing_fumbles_lost', 'rushing_first_downs',\n",
    "       'rushing_2pt_conversions', 'receptions', 'targets',\n",
    "       'receiving_yards', 'receiving_tds',\n",
    "       'receiving_fumbles_lost', 'receiving_air_yards',\n",
    "       'receiving_yards_after_catch', 'receiving_first_downs',\n",
    "       'receiving_2pt_conversions', 'special_teams_tds', 'fantasy_points',\n",
    "       'rrtd']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"targetPPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('player_display_name')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"targetPPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=dictParam[\"hidden_layer_sizes\"], activation=dictParam[\"activation\"], solver=dictParam[\"solver\"], max_iter=dictParam[\"max_iter\"])\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = mlp.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    # print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    # for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "    #     print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(mlp, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    # print(\"Feature importances in descending order:\")\n",
    "    # for feature, importance in sorted_importances:\n",
    "    #     print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, mlp, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'hidden_layer_sizes': [(32,32), (64,32), (64), (64,64)],\n",
    "      'activation': ['tanh', 'identity', 'logistic', 'relu'],\n",
    "      'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "      'max_iter': [100, 200, 500]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  mlp = MLPRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(mlp, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  # print(\"Best things:\", grid_search.best_params_)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  # print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  # print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  dfFantasyCopy = dfFantasy.copy()\n",
    "\n",
    "  dfFantasyCopy = correctData(dfFantasyCopy, ppr)\n",
    "\n",
    "  dfFantasyCopy = putAV(dfFantasyCopy, dfGrades)\n",
    "  \n",
    "  dfFantasyCopy = makeCorrectShift(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.loc[dfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  dfFantasyCopy = removeUnwanted(dfFantasyCopy, \"WRTE\")\n",
    "\n",
    "  dfFantasyCopy = dfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleQB = getScaleBack(dfFantasyCopy)\n",
    "\n",
    "  dfFantasyCopy[dfFantasyCopy.columns] = scaler.fit_transform(dfFantasyCopy[dfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramQB = {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'max_iter': 300, 'solver': 'adam'}\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  qbArray = machineLearning(dfFantasyCopy, scaleQB, paramQB)\n",
    "  num = qbArray[0]\n",
    "  qbModel = qbArray[1]\n",
    "\n",
    "  print(\"wrte score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(qbModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/wrte models/wrteModelPPR.joblib\")\n",
    "#print(dfFantasyRB.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'k'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 256\u001b[0m\n\u001b[1;32m    252\u001b[0m KdfFantasyCopy \u001b[38;5;241m=\u001b[39m correctData(KdfFantasyCopy, ppr)\n\u001b[1;32m    254\u001b[0m KdfFantasyCopy \u001b[38;5;241m=\u001b[39m putAV(KdfFantasyCopy, dfGrades)\n\u001b[0;32m--> 256\u001b[0m KdfFantasyCopy \u001b[38;5;241m=\u001b[39m \u001b[43mmakeCorrectShift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKdfFantasyCopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m KdfFantasyCopy \u001b[38;5;241m=\u001b[39m KdfFantasyCopy\u001b[38;5;241m.\u001b[39mloc[KdfFantasyCopy[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2012\u001b[39m]\n\u001b[1;32m    260\u001b[0m KdfFantasyCopy \u001b[38;5;241m=\u001b[39m removeUnwanted(KdfFantasyCopy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 115\u001b[0m, in \u001b[0;36mmakeCorrectShift\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    112\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargetPPG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#shifts it forward a year (for example 2011 goes to 2012)\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m df[shifters] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mshifters\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    116\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1771\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1769\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1770\u001b[0m     )\n\u001b[0;32m-> 1771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/base.py:239\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(key)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)):\n\u001b[1;32m    238\u001b[0m         bad_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(key)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(bad_keys)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(\u001b[38;5;28mlist\u001b[39m(key), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'k'\""
     ]
    }
   ],
   "source": [
    "#K ML MODEL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "\n",
    "#scaler to scale data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#read csv files into pandas\n",
    "KdfFantasy = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/final position group data/final_kicking_data.csv\")\n",
    "KdfFantasy.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = KdfFantasy.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_cols:\n",
    "    KdfFantasy[column].fillna(KdfFantasy[column].mean(), inplace=True)\n",
    "dfGrades = pd.read_csv(\"/Users/kmaran3/Dropbox/Darkhorse/approximate value data/AVbyPositionGroup.csv\")\n",
    "\n",
    "def correctData(df, pprTF):\n",
    "  #cols to make per game\n",
    "  cols = ['Age','FGA1', 'FGM1', 'FGA2',\n",
    "       'FGM2', 'FGA3', 'FGM3', 'FGA4', 'FGM4', 'FGA5', 'FGM5', 'FGA', 'FGM',\n",
    "       'XPA', 'XPM']\n",
    "\n",
    "  #basing data if ppr or not\n",
    "  if pprTF == 2:\n",
    "    pass\n",
    "  elif pprTF == 0:\n",
    "    pass\n",
    "  elif pprTF == 1:\n",
    "    pass\n",
    "\n",
    "    \n",
    "  #adding ppg column\n",
    "  df.loc[:, 'PPG'] = df['fantasy_points'] / df['G']\n",
    "\n",
    "\n",
    "  #make all columns in a per game basis\n",
    "  for col in cols:\n",
    "    df.loc[:, col] = df[col] / df['G'] \n",
    "\n",
    "\n",
    "  #only players with more than 7 games.\n",
    "  df = df[df.G > 7]\n",
    "  df = df[df.fantasy_points >= 0]\n",
    "\n",
    "  df = df[df.PPG > 1.5]\n",
    "  \n",
    "\n",
    "  return df\n",
    "\n",
    "def putAV(df, dfAV):\n",
    "  #years to iterate through\n",
    "  yearsBig = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "  teams = [\"crd\", \"atl\", \"rav\", \"buf\", \"car\", \"chi\", \"cin\", \"cle\", \"dal\", \"den\", \"det\", \"gnb\", \"htx\", \"clt\", \"jax\", \"kan\", \"rai\", \"sdg\", \"ram\", \"mia\", \"min\", \"nwe\", \"nor\", \"nyg\", \"nyj\", \"phi\", \"pit\", \"sfo\", \"sea\", \"tam\", \"oti\", \"was\"]\n",
    "\n",
    "  #columns wanted to add\n",
    "  columns = [\"oline\", \"qb\", \"rb\", \"wrte\", \"dst\"]\n",
    "  df[columns] = np.nan\n",
    "\n",
    "  #gets rid of nan for these columns, as when we drop nan we want to save these.\n",
    "  for colNow in columns:\n",
    "    df.loc[df[\"season\"] == 2013, colNow] = \"no\"\n",
    "\n",
    "\n",
    "\n",
    "  #iterates through years\n",
    "  for year in yearsBig:\n",
    "\n",
    "    #assigns df of AVS to only include current year\n",
    "    dfCurr = dfAV[dfAV.season == year].copy()\n",
    "    \n",
    "    #iterates through team list\n",
    "    for teamNow in teams:\n",
    "      #makes the df\n",
    "      dfCurrNew = dfCurr[dfCurr.team == teamNow]\n",
    "      \n",
    "      #iterates through columns and adds AV\n",
    "      for colNow in columns:\n",
    "        #locate correct year and team rows\n",
    "        condition = (df[\"season\"] == year) & (df[\"team\"] == teamNow)\n",
    "\n",
    "        #set these rows to correct values\n",
    "        df.loc[condition, colNow] = dfCurrNew.iloc[0][colNow]\n",
    "\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#removes unneccesary stats\n",
    "def removeUnwanted(dfPos, pos):\n",
    "  dfPos = dfPos.drop(columns=['season',\"G\", \"GS\", \"fantasy_points\", \"Player\", \"team\", \"Pos\"])\n",
    "  return dfPos\n",
    "\n",
    "#shifts data forward one year\n",
    "def makeCorrectShift(df):\n",
    "  shifters = ['PPG','Player', 'team', 'Age', 'Pos', 'G', 'GS', 'FGA1', 'FGM1', 'FGA2',\n",
    "       'FGM2', 'FGA3', 'FGM3', 'FGA4', 'FGM4', 'FGA5', 'FGM5', 'FGA', 'FGM',\n",
    "       'Lng', 'FG%', 'XPA', 'XPM', 'XP%', 'season', 'k', 'fantasy_points']\n",
    "  \n",
    "  #adds target variable\n",
    "  df[\"targetPPG\"] = df[\"PPG\"]\n",
    "  \n",
    "  #shifts it forward a year (for example 2011 goes to 2012)\n",
    "  df[shifters] = df.groupby('Player')[shifters].shift(1)\n",
    "  df = df.dropna()\n",
    "\n",
    "  return df\n",
    "\n",
    "#where machine learning is done. returns the model and score.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def machineLearning(df, arr, dictParam):\n",
    "    # Define predictors excluding the target variable\n",
    "    predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "    # Split the data\n",
    "    x = df[predictors].values\n",
    "    y = df[\"targetPPG\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Initialize and train MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=dictParam[\"hidden_layer_sizes\"], activation=dictParam[\"activation\"], solver=dictParam[\"solver\"], max_iter=dictParam[\"max_iter\"])\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict_test = mlp.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, predict_test)\n",
    "\n",
    "    predict_test_unscaled = predict_test * (arr[1] - arr[0]) + arr[0]\n",
    "    y_test_unscaled = y_test * (arr[1] - arr[0]) + arr[0]\n",
    "\n",
    "    print(\"Predicted vs Actual PPG (unscaled):\")\n",
    "    for pred, actual in zip(predict_test_unscaled, y_test_unscaled):\n",
    "        print(f\"Predicted: {pred:.2f}, Actual: {actual:.2f}\")\n",
    "\n",
    "    # Calculate permutation importance\n",
    "    r = permutation_importance(mlp, x_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "    # Organize importances\n",
    "    importance_dict = {name: score for name, score in zip(predictors, r.importances_mean)}\n",
    "    sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print sorted importances\n",
    "    print(\"Feature importances in descending order:\")\n",
    "    for feature, importance in sorted_importances:\n",
    "        print(f\"{feature}: {importance}\")\n",
    "    \n",
    "\n",
    "\n",
    "    return [mae, mlp, sorted_importances]\n",
    "\n",
    "# Example usage of the modified function\n",
    "\n",
    "\n",
    "def getBestParams(df, arr):\n",
    "\n",
    "  #make the predictors and data and test sets correctly\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  \n",
    "  #make the parameters to search over. for hidden_layer_sizes, I experimented with alot and the ones listed now is just final set of experiment.\n",
    "  \n",
    "  grid = {\n",
    "      'hidden_layer_sizes': [(32,32), (64,32), (64), (64,64)],\n",
    "      'activation': ['tanh', 'identity', 'logistic', 'relu'],\n",
    "      'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "      'max_iter': [100, 200, 500]\n",
    "  }\n",
    "\n",
    "  #create an MLPRegressor object\n",
    "  mlp = MLPRegressor()\n",
    "\n",
    "  #create a GridSearchCV object and fit it to the training data\n",
    "  grid_search = GridSearchCV(mlp, param_grid=grid, cv=5, n_jobs=-1)\n",
    "  grid_search.fit(x_train, y_train)\n",
    "\n",
    "  print(\"Best things:\", grid_search.best_params_)\n",
    "\n",
    "  #the best model to make predictions on the test data and evaluate performance\n",
    "  y_pred = grid_search.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale, uses a reverse of original formula\n",
    "  for i in range(len(y_pred)):\n",
    "    y_pred[i] = (y_pred[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "\n",
    "  print(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "  return grid_search.best_params_\n",
    "\n",
    "#gets original value for fantasy points for predictions.\n",
    "def getScaleBack(df):\n",
    "  #index of column\n",
    "  column_index = df.columns.get_loc(\"PPG\")\n",
    "\n",
    "  #min value of column:\n",
    "  min_value = df[\"PPG\"].min()\n",
    "\n",
    "  #scaling valye of column\n",
    "  #scaling_factor = scaler.scale_[column_index]\n",
    "  max_value = df[\"PPG\"].max()\n",
    "\n",
    "  #array to be used later to scale each data\n",
    "  arr = [min_value, max_value]\n",
    "\n",
    "  return arr\n",
    "\n",
    "def test(df, model, arr):\n",
    "  #make columns everything but target\n",
    "  predictors = [col for col in df.columns if col != \"targetPPG\"]\n",
    "\n",
    "\n",
    "  #make train and test sets\n",
    "  x = df[predictors].values\n",
    "  y = df[\"targetPPG\"].values\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=40)\n",
    "\n",
    "  #make the predictions\n",
    "  predict_test = model.predict(x_test)\n",
    "\n",
    "  #inverse transform the scaled predictions to get the original scale by reversing formula\n",
    "  for i in range(len(predict_test)):\n",
    "    predict_test[i] = (predict_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "  for i in range(len(y_test)):\n",
    "    y_test[i] = (y_test[i]*(arr[1] - arr[0])) + arr[0]\n",
    "\n",
    "  #average error \n",
    "  mae = mean_absolute_error(y_test, predict_test)\n",
    "  print(\"test \", mae)\n",
    "\n",
    "#if ppr is 0, than it is non ppr. if 1, then it is half ppr. if 2, full ppr. loops through each.\n",
    "for ppr in [0,1,2]:\n",
    "\n",
    "  KdfFantasyCopy = KdfFantasy.copy()\n",
    "\n",
    "  KdfFantasyCopy = correctData(KdfFantasyCopy, ppr)\n",
    "\n",
    "  KdfFantasyCopy = putAV(KdfFantasyCopy, dfGrades)\n",
    "\n",
    "  KdfFantasyCopy = makeCorrectShift(KdfFantasyCopy)\n",
    "\n",
    "  KdfFantasyCopy = KdfFantasyCopy.loc[KdfFantasyCopy[\"season\"] != 2012]\n",
    "\n",
    "  KdfFantasyCopy = removeUnwanted(KdfFantasyCopy, \"K\")\n",
    "\n",
    "  KdfFantasyCopy = KdfFantasyCopy.reset_index(drop=True)\n",
    "\n",
    "  #gets fantasy_points_ppr scale per each position\n",
    "  scaleK = getScaleBack(KdfFantasyCopy)\n",
    "\n",
    "  KdfFantasyCopy[KdfFantasyCopy.columns] = scaler.fit_transform(KdfFantasyCopy[KdfFantasyCopy.columns])\n",
    "\n",
    "  #obtained by running the getBestParams function per each respective position\n",
    "  paramK = {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'max_iter': 300, 'solver': 'adam'}\n",
    "\n",
    "  #makes array of model and score, then prints it\n",
    "  KArray = machineLearning(KdfFantasyCopy, scaleK, paramK)\n",
    "  num = KArray[0]\n",
    "  KModel = KArray[1]\n",
    "\n",
    "  print(\"k score(ppg off on average per player): \", num)\n",
    "  if ppr == 0:\n",
    "      joblib.dump(KModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/k models/kModelNonPPR.joblib\")\n",
    "  elif ppr == 1:\n",
    "      joblib.dump(KModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/k models/kModelHalfPPR.joblib\")\n",
    "  elif ppr == 2:\n",
    "      joblib.dump(KModel, \"/Users/kmaran3/Dropbox/Darkhorse/Models/k models/kModelPPR.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
